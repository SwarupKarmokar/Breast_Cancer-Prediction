{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis = 1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,input_sz, h1, h2, h3, out_sz):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_sz, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.out = nn.Linear(h3, out_sz)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "my_model = Model(input_sz=30, h1=60, h2=20, h3=10 ,out_sz=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=30, out_features=60, bias=True)\n",
       "  (fc2): Linear(in_features=60, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0 loss: 0.7321192026138306\n",
      "epochs: 10 loss: 0.6688722968101501\n",
      "epochs: 20 loss: 0.6431043148040771\n",
      "epochs: 30 loss: 0.6106914281845093\n",
      "epochs: 40 loss: 0.5559884309768677\n",
      "epochs: 50 loss: 0.43485021591186523\n",
      "epochs: 60 loss: 0.3024318516254425\n",
      "epochs: 70 loss: 0.23660768568515778\n",
      "epochs: 80 loss: 0.19715847074985504\n",
      "epochs: 90 loss: 0.18977168202400208\n",
      "epochs: 100 loss: 0.18155665695667267\n",
      "epochs: 110 loss: 0.17618612945079803\n",
      "epochs: 120 loss: 0.17166152596473694\n",
      "epochs: 130 loss: 0.16758224368095398\n",
      "epochs: 140 loss: 0.1640927642583847\n",
      "epochs: 150 loss: 0.16088899970054626\n",
      "epochs: 160 loss: 0.15821512043476105\n",
      "epochs: 170 loss: 0.15487352013587952\n",
      "epochs: 180 loss: 0.15207122266292572\n",
      "epochs: 190 loss: 0.14990685880184174\n",
      "epochs: 200 loss: 0.14795547723770142\n",
      "epochs: 210 loss: 0.14522281289100647\n",
      "epochs: 220 loss: 0.14147663116455078\n",
      "epochs: 230 loss: 0.14113208651542664\n",
      "epochs: 240 loss: 0.138811394572258\n",
      "epochs: 250 loss: 0.13476580381393433\n",
      "epochs: 260 loss: 0.13276149332523346\n",
      "epochs: 270 loss: 0.13043510913848877\n",
      "epochs: 280 loss: 0.1277465969324112\n",
      "epochs: 290 loss: 0.1253771036863327\n",
      "epochs: 299 loss: 0.12466473877429962\n",
      "\n",
      "Duration: 2 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = my_model.forward(X_train)\n",
    "    loss = criterion(y_pred,y_train)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(f\"epochs: {i} loss: {loss}\")\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"epochs: {i} loss: {loss}\")\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    y_eval = my_model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26387670636177063\n"
     ]
    }
   ],
   "source": [
    "print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([-1.0413,  4.3137]) predicted_y: 1 real_y: 1\n",
      "2. tensor([0.7628, 2.3748]) predicted_y: 1 real_y: 1\n",
      "3. tensor([-0.9594,  4.4249]) predicted_y: 1 real_y: 1\n",
      "4. tensor([ 4.9696, -1.9116]) predicted_y: 0 real_y: 0\n",
      "5. tensor([-2.8374,  7.0569]) predicted_y: 1 real_y: 1\n",
      "6. tensor([-1.1339,  4.9737]) predicted_y: 1 real_y: 1\n",
      "7. tensor([-2.2632,  5.2900]) predicted_y: 1 real_y: 1\n",
      "8. tensor([ 7.4569, -1.6324]) predicted_y: 0 real_y: 0\n",
      "9. tensor([-0.8093,  4.1839]) predicted_y: 1 real_y: 1\n",
      "10. tensor([-2.4422,  6.0237]) predicted_y: 1 real_y: 1\n",
      "11. tensor([2.2333, 0.8450]) predicted_y: 0 real_y: 0\n",
      "12. tensor([-1.1915,  4.4087]) predicted_y: 1 real_y: 1\n",
      "13. tensor([-0.4323,  3.2082]) predicted_y: 1 real_y: 1\n",
      "14. tensor([-0.4801,  3.7923]) predicted_y: 1 real_y: 1\n",
      "15. tensor([ 4.9129, -1.3440]) predicted_y: 0 real_y: 0\n",
      "16. tensor([-1.2701,  3.7950]) predicted_y: 1 real_y: 1\n",
      "17. tensor([-0.7468,  4.2652]) predicted_y: 1 real_y: 1\n",
      "18. tensor([-2.3468,  5.7642]) predicted_y: 1 real_y: 1\n",
      "19. tensor([ 13.9045, -11.5195]) predicted_y: 0 real_y: 0\n",
      "20. tensor([0.9392, 2.3039]) predicted_y: 1 real_y: 0\n",
      "21. tensor([0.1887, 2.2058]) predicted_y: 1 real_y: 1\n",
      "22. tensor([-1.9515,  4.8360]) predicted_y: 1 real_y: 1\n",
      "23. tensor([0.0221, 2.6999]) predicted_y: 1 real_y: 1\n",
      "24. tensor([-1.2661,  4.5762]) predicted_y: 1 real_y: 1\n",
      "25. tensor([3.7834, 0.5474]) predicted_y: 0 real_y: 0\n",
      "26. tensor([0.3498, 2.2683]) predicted_y: 1 real_y: 1\n",
      "27. tensor([ 3.3143, -0.5721]) predicted_y: 0 real_y: 0\n",
      "28. tensor([-2.9819,  7.0081]) predicted_y: 1 real_y: 1\n",
      "29. tensor([ 5.6683, -2.8069]) predicted_y: 0 real_y: 0\n",
      "30. tensor([0.4873, 1.6448]) predicted_y: 1 real_y: 0\n",
      "31. tensor([-1.1255,  4.7248]) predicted_y: 1 real_y: 1\n",
      "32. tensor([1.8351, 0.5592]) predicted_y: 0 real_y: 0\n",
      "33. tensor([0.9209, 1.8289]) predicted_y: 1 real_y: 1\n",
      "34. tensor([ 4.0872, -0.4889]) predicted_y: 0 real_y: 0\n",
      "35. tensor([-2.0298,  5.9831]) predicted_y: 1 real_y: 1\n",
      "36. tensor([-2.5891,  6.3326]) predicted_y: 1 real_y: 1\n",
      "37. tensor([ 4.7817, -1.0366]) predicted_y: 0 real_y: 0\n",
      "38. tensor([1.1487, 1.6588]) predicted_y: 1 real_y: 0\n",
      "39. tensor([ 8.6746, -4.3002]) predicted_y: 0 real_y: 0\n",
      "40. tensor([ 13.8979, -10.3302]) predicted_y: 0 real_y: 0\n",
      "41. tensor([3.6592, 0.1473]) predicted_y: 0 real_y: 0\n",
      "42. tensor([-1.0056,  4.0761]) predicted_y: 1 real_y: 1\n",
      "43. tensor([-0.9077,  4.1113]) predicted_y: 1 real_y: 1\n",
      "44. tensor([1.5596, 1.5302]) predicted_y: 0 real_y: 1\n",
      "45. tensor([-2.5139,  6.0882]) predicted_y: 1 real_y: 1\n",
      "46. tensor([-1.0659,  4.1189]) predicted_y: 1 real_y: 1\n",
      "47. tensor([ 8.7490, -5.7179]) predicted_y: 0 real_y: 0\n",
      "48. tensor([2.0163, 0.8277]) predicted_y: 0 real_y: 1\n",
      "49. tensor([0.2428, 3.4382]) predicted_y: 1 real_y: 0\n",
      "50. tensor([-0.3351,  3.0941]) predicted_y: 1 real_y: 1\n",
      "51. tensor([ 6.0334, -2.2336]) predicted_y: 0 real_y: 0\n",
      "52. tensor([1.9659, 0.4358]) predicted_y: 0 real_y: 1\n",
      "53. tensor([1.1053, 1.6266]) predicted_y: 1 real_y: 1\n",
      "54. tensor([ 8.0811, -3.7210]) predicted_y: 0 real_y: 0\n",
      "55. tensor([-1.8523,  5.3429]) predicted_y: 1 real_y: 1\n",
      "56. tensor([-1.2892,  4.8075]) predicted_y: 1 real_y: 1\n",
      "57. tensor([ 5.7543, -2.4974]) predicted_y: 0 real_y: 0\n",
      "58. tensor([ 7.4686, -3.2433]) predicted_y: 0 real_y: 0\n",
      "59. tensor([-2.1981,  6.1574]) predicted_y: 1 real_y: 1\n",
      "60. tensor([-1.1295,  4.6237]) predicted_y: 1 real_y: 1\n",
      "61. tensor([ 4.0603, -1.2916]) predicted_y: 0 real_y: 0\n",
      "62. tensor([1.9032, 0.8080]) predicted_y: 0 real_y: 0\n",
      "63. tensor([0.6890, 1.8227]) predicted_y: 1 real_y: 1\n",
      "64. tensor([-1.6971,  5.0344]) predicted_y: 1 real_y: 1\n",
      "65. tensor([ 9.7620, -5.8761]) predicted_y: 0 real_y: 0\n",
      "66. tensor([0.9314, 1.5777]) predicted_y: 1 real_y: 1\n",
      "67. tensor([1.2927, 0.9599]) predicted_y: 0 real_y: 1\n",
      "68. tensor([11.1081, -8.0304]) predicted_y: 0 real_y: 0\n",
      "69. tensor([ 5.1185, -0.3270]) predicted_y: 0 real_y: 0\n",
      "70. tensor([-0.7118,  4.2094]) predicted_y: 1 real_y: 1\n",
      "71. tensor([ 6.5457, -2.4210]) predicted_y: 0 real_y: 0\n",
      "72. tensor([0.1086, 3.1144]) predicted_y: 1 real_y: 1\n",
      "73. tensor([-2.1705,  6.1783]) predicted_y: 1 real_y: 1\n",
      "74. tensor([-1.5781,  5.1151]) predicted_y: 1 real_y: 1\n",
      "75. tensor([ 5.4947, -1.2982]) predicted_y: 0 real_y: 0\n",
      "76. tensor([12.8005, -8.3290]) predicted_y: 0 real_y: 0\n",
      "77. tensor([-1.5205,  5.3835]) predicted_y: 1 real_y: 1\n",
      "78. tensor([1.9465, 2.0892]) predicted_y: 1 real_y: 0\n",
      "79. tensor([ 7.5140, -3.3978]) predicted_y: 0 real_y: 0\n",
      "80. tensor([0.8112, 2.6477]) predicted_y: 1 real_y: 1\n",
      "81. tensor([0.3710, 2.3917]) predicted_y: 1 real_y: 1\n",
      "82. tensor([0.7615, 2.3106]) predicted_y: 1 real_y: 1\n",
      "83. tensor([0.3874, 3.1408]) predicted_y: 1 real_y: 1\n",
      "84. tensor([-1.3698,  4.5684]) predicted_y: 1 real_y: 1\n",
      "85. tensor([0.0255, 3.2139]) predicted_y: 1 real_y: 1\n",
      "86. tensor([-3.0340,  7.1279]) predicted_y: 1 real_y: 1\n",
      "87. tensor([ 3.6461, -1.7330]) predicted_y: 0 real_y: 0\n",
      "88. tensor([-1.1892,  4.3929]) predicted_y: 1 real_y: 1\n",
      "89. tensor([ 8.9695, -6.0507]) predicted_y: 0 real_y: 0\n",
      "90. tensor([2.7077, 0.8693]) predicted_y: 0 real_y: 0\n",
      "91. tensor([1.0327, 2.3184]) predicted_y: 1 real_y: 1\n",
      "92. tensor([ 3.5488, -1.2037]) predicted_y: 0 real_y: 0\n",
      "93. tensor([ 3.6339, -1.5578]) predicted_y: 0 real_y: 0\n",
      "94. tensor([1.3896, 0.9472]) predicted_y: 0 real_y: 1\n",
      "95. tensor([-2.3386,  5.7236]) predicted_y: 1 real_y: 1\n",
      "96. tensor([-2.4294,  5.6982]) predicted_y: 1 real_y: 1\n",
      "97. tensor([1.1854, 1.6227]) predicted_y: 1 real_y: 1\n",
      "98. tensor([-0.8240,  4.9967]) predicted_y: 1 real_y: 1\n",
      "99. tensor([ 3.4627, -0.8467]) predicted_y: 0 real_y: 0\n",
      "100. tensor([ 4.3019, -0.0838]) predicted_y: 0 real_y: 0\n",
      "101. tensor([ 7.1078, -2.5433]) predicted_y: 0 real_y: 0\n",
      "102. tensor([-2.3196,  5.6495]) predicted_y: 1 real_y: 1\n",
      "103. tensor([-1.7049,  5.3621]) predicted_y: 1 real_y: 1\n",
      "104. tensor([-2.5717,  5.8291]) predicted_y: 1 real_y: 1\n",
      "105. tensor([0.8730, 1.5418]) predicted_y: 1 real_y: 1\n",
      "106. tensor([-0.2255,  2.9483]) predicted_y: 1 real_y: 1\n",
      "107. tensor([-1.3705,  4.9308]) predicted_y: 1 real_y: 1\n",
      "108. tensor([1.2883, 1.5515]) predicted_y: 1 real_y: 1\n",
      "109. tensor([0.2744, 3.3329]) predicted_y: 1 real_y: 1\n",
      "110. tensor([0.4064, 2.7042]) predicted_y: 1 real_y: 1\n",
      "111. tensor([-2.7258,  6.6558]) predicted_y: 1 real_y: 1\n",
      "112. tensor([-2.8655,  6.8548]) predicted_y: 1 real_y: 1\n",
      "113. tensor([0.7152, 2.7231]) predicted_y: 1 real_y: 1\n",
      "114. tensor([ 5.8813, -2.1149]) predicted_y: 0 real_y: 0\n",
      "115. tensor([1.9181, 0.8468]) predicted_y: 0 real_y: 1\n",
      "116. tensor([-1.9026,  5.5772]) predicted_y: 1 real_y: 1\n",
      "117. tensor([-1.0181,  4.6015]) predicted_y: 1 real_y: 1\n",
      "118. tensor([2.5805, 0.5034]) predicted_y: 0 real_y: 0\n",
      "119. tensor([ 4.8107, -2.1857]) predicted_y: 0 real_y: 0\n",
      "120. tensor([10.5328, -6.7054]) predicted_y: 0 real_y: 0\n",
      "121. tensor([10.6693, -3.0511]) predicted_y: 0 real_y: 0\n",
      "122. tensor([ 8.6900, -4.8179]) predicted_y: 0 real_y: 0\n",
      "123. tensor([ 6.3502, -1.7714]) predicted_y: 0 real_y: 0\n",
      "124. tensor([-1.8337,  5.2757]) predicted_y: 1 real_y: 1\n",
      "125. tensor([0.8390, 2.4806]) predicted_y: 1 real_y: 1\n",
      "126. tensor([-2.6283,  6.2086]) predicted_y: 1 real_y: 1\n",
      "127. tensor([-2.8264,  6.7997]) predicted_y: 1 real_y: 1\n",
      "128. tensor([-2.3191,  5.6507]) predicted_y: 1 real_y: 1\n",
      "129. tensor([0.7378, 3.3330]) predicted_y: 1 real_y: 1\n",
      "130. tensor([0.0114, 3.3320]) predicted_y: 1 real_y: 1\n",
      "131. tensor([10.4466, -6.2281]) predicted_y: 0 real_y: 0\n",
      "132. tensor([ 8.0470, -4.4122]) predicted_y: 0 real_y: 0\n",
      "133. tensor([2.4397, 1.1814]) predicted_y: 0 real_y: 1\n",
      "134. tensor([-0.2296,  3.3880]) predicted_y: 1 real_y: 1\n",
      "135. tensor([0.1476, 3.1328]) predicted_y: 1 real_y: 1\n",
      "136. tensor([-0.8064,  3.8497]) predicted_y: 1 real_y: 1\n",
      "137. tensor([3.7535, 1.6006]) predicted_y: 0 real_y: 0\n",
      "138. tensor([ 2.8499, -0.0517]) predicted_y: 0 real_y: 0\n",
      "139. tensor([11.9187, -8.4802]) predicted_y: 0 real_y: 0\n",
      "140. tensor([-2.8011,  6.3446]) predicted_y: 1 real_y: 1\n",
      "141. tensor([ 6.3292, -2.8823]) predicted_y: 0 real_y: 0\n",
      "142. tensor([-0.6654,  3.5685]) predicted_y: 1 real_y: 1\n",
      "143. tensor([10.8833, -8.7038]) predicted_y: 0 real_y: 0\n",
      "144. tensor([0.7294, 2.1028]) predicted_y: 1 real_y: 1\n",
      "145. tensor([0.3210, 2.4795]) predicted_y: 1 real_y: 1\n",
      "146. tensor([1.0483, 2.2883]) predicted_y: 1 real_y: 1\n",
      "147. tensor([2.1850, 1.3974]) predicted_y: 0 real_y: 1\n",
      "148. tensor([-1.6731,  5.2752]) predicted_y: 1 real_y: 1\n",
      "149. tensor([1.8316, 1.1181]) predicted_y: 0 real_y: 1\n",
      "150. tensor([0.9225, 1.8805]) predicted_y: 1 real_y: 1\n",
      "151. tensor([-2.4668,  6.1848]) predicted_y: 1 real_y: 1\n",
      "152. tensor([ 4.8844, -0.9220]) predicted_y: 0 real_y: 0\n",
      "153. tensor([ 4.0796, -1.7944]) predicted_y: 0 real_y: 0\n",
      "154. tensor([ 7.6662, -3.3610]) predicted_y: 0 real_y: 0\n",
      "155. tensor([-2.7297,  6.2459]) predicted_y: 1 real_y: 1\n",
      "156. tensor([ 8.4128, -4.0823]) predicted_y: 0 real_y: 0\n",
      "157. tensor([-2.2210,  5.5693]) predicted_y: 1 real_y: 1\n",
      "158. tensor([ 5.7522, -2.0975]) predicted_y: 0 real_y: 0\n",
      "159. tensor([-2.4501,  6.0743]) predicted_y: 1 real_y: 1\n",
      "160. tensor([-2.6274,  6.7681]) predicted_y: 1 real_y: 1\n",
      "161. tensor([0.7256, 2.4722]) predicted_y: 1 real_y: 0\n",
      "162. tensor([-1.3210,  4.5982]) predicted_y: 1 real_y: 1\n",
      "163. tensor([-2.6405,  6.2193]) predicted_y: 1 real_y: 1\n",
      "164. tensor([ 9.1068, -4.8827]) predicted_y: 0 real_y: 0\n",
      "165. tensor([ 6.0281, -1.9407]) predicted_y: 0 real_y: 0\n",
      "166. tensor([-3.0381,  8.4247]) predicted_y: 1 real_y: 0\n",
      "167. tensor([-0.5538,  3.3795]) predicted_y: 1 real_y: 1\n",
      "168. tensor([-0.9110,  4.6867]) predicted_y: 1 real_y: 1\n",
      "169. tensor([-2.3363,  5.6844]) predicted_y: 1 real_y: 1\n",
      "170. tensor([0.9361, 2.6161]) predicted_y: 1 real_y: 0\n",
      "171. tensor([-0.3269,  3.1726]) predicted_y: 1 real_y: 0\n",
      "we got 153 correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_eval = my_model.forward(data)\n",
    "        print(f'{i+1}. {str(y_eval)} predicted_y: {y_eval.argmax().item()} real_y: {y_test[i]}')\n",
    "        \n",
    "        prediction.append(y_eval.argmax().item())\n",
    "        if y_eval.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'we got {correct} correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  9]\n",
      " [ 9 96]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        66\n",
      "           1       0.91      0.91      0.91       105\n",
      "\n",
      "    accuracy                           0.89       171\n",
      "   macro avg       0.89      0.89      0.89       171\n",
      "weighted avg       0.89      0.89      0.89       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), 'Cancer_prediction.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.tensor([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
    "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
    "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
    "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
    "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
       "         3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
       "         8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
       "         3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
       "         1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = my_model(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.1081, -8.0304]])\n",
      "0\n",
      "you dont have cancer\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print(prediction.argmax().item())\n",
    "\n",
    "if prediction.argmax().item() == 0:\n",
    "    print('you dont have cancer')\n",
    "else:\n",
    "    print('you have cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
